<!DOCTYPE html>
<html lang="zh-CN">
 <head>
     <meta charset="utf-8" />
  <title>Python爬取不确定页数网页 | ZhangXiong</title>
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport" />
  <link rel="stylesheet" href="https://xiong-zh.github.io/styles/main.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
   <script src="https://cdn.staticfile.org/highlight.js/9.15.9/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
 </head>
 <body>
     <div class="sidebar animated fadeInDown">
   <div class="logo-title">
    <div class="title">
     <img src="https://xiong-zh.github.io/images/avatar.png?v=1582636188884" style="width:127px;" />

     <h3 title=""><a href="/">张雄</a></h3>

     <div class="description">
      <p>当地一个比较有趣的小法师，最近在在努力学习厉害的魔法。</p>
     </div>
    </div>
   </div>
   <ul class="social-links">


    

    <li><a href="https://twitter.com/imzhangxiong"><i class="fa fa-twitter"></i></a></li>
 
    

    <li><a href="https://www.facebook.com/xiong.zh.397"><i class="fa fa-facebook"></i></a></li>
 
    

    <li><a href="https://github.com/xiong-zh"><i class="fa fa-github"></i></a></li>
 
    

    

    

    

    <li><a href="https://weibo.com/zhangxiongblog"><i class="fa fa-weibo"></i></a></li>
 
    

    

    

   </ul>
   <div class="footer">
    <div class="by_farbox">
   <a href="http://beian.miit.gov.cn/" target="_blank">滇ICP备20001109号</a> | Copyright © 2020 <a href="https://zhangxiong.net/" target="_blank">｜zhangxiong </a> 版权所有
    </div>
    
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-156420077-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-156420077-1');
</script>


    </div>
   </div>
  </div>
  <div class="main">
     <div class="page-top animated fadeInDown">
    <div class="nav">
    
     <li><a  href="/">回到首页</a></li>

     <li><a  href="/archives">历史归档</a></li>

     <li><a  href="/tags">所有标签</a></li>

     <li><a  href="/documents/">后端图谱</a></li>

     <li><a  href="/about/">关于｜友链</a></li>

    </div>
    <div class="information">
     <div class="back_btn">
      <li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li>
     </div>
    </div>
   </div>
   <div class="autopagerize_page_element">
    <div class="content">
     <div class="post-page">
      <div class="post animated fadeInDown">
       <div class="post-title">
        <h3><a>Python爬取不确定页数网页</a></h3>
       </div>
       <div class="post-content">
        <p>我们通常遇到的网站页数展现形式有这么几种：</p>
<ul>
<li>第一种是直观地显示所有页数，显示在页面上。</li>
<li>第二种是不直观显示网页总页数，需要抓包才可以看到，一般来说会有一个 <code>totalPage</code> 参数。</li>
<li><strong>第三种是不知道具体有多少页的网页。</strong></li>
</ul>
<!-- more -->
<p>本文详细分析了如何爬取<strong>不知道具体有多少页的网站</strong>，然后用 scrapy 框架实现了这个过程。</p>
<h2 id="一-问题分析">一、问题分析</h2>
<p>我们通常遇到的网站页数展现形式有这么几种：</p>
<ul>
<li>第一种是直观地显示所有页数，显示在页面上。</li>
<li>第二种是不直观显示网页总页数，需要抓包才可以看到，一般来说会有一个 <code>totalPage</code> 参数。</li>
<li><strong>第三种是不知道具体有多少页的网页。</strong></li>
</ul>
<p>对于，前两种形式的网页，爬取方法非常简单，使用 For 循环从首页爬到尾页就行了，第三种形式则不适用，因为不知道尾页的页数，所以循环到哪一页结束无法判断。</p>
<h2 id="二-解决方案">二、解决方案</h2>
<p>这里有两种解决方式：</p>
<ul>
<li>第一种方式：使用 For 循环，尾页的页数设置一个较大的参数，足够循环爬完所有页面。</li>
<li>第二种方法：使用 While 循环，可以结合 break 语句，也可以设起始循环判断条件为 True，从头开始循环爬取直到爬完最后一页，然后更改判断条件为 False 跳出循环，结束爬取。</li>
</ul>
<h2 id="三-实际案例-scrapy-实现">三、实际案例 ——scrapy 实现</h2>
<h3 id="1-for-循环实现">1、For 循环实现</h3>
<p>Scrapy 中使用 For 循环递归爬取的思路非常简单，即先批量生成所有请求的 URL，包括最后无效的 URL，后续在 parse 方法中添加 if 判断过滤无效请求。</p>
<p><strong>由于 Scrapy 依赖于 Twisted 框架，采用的是异步请求处理方式，可以边发送请求边解析内容，不会被阻塞，但是这种方法会发送很多无用请求。</strong></p>
<pre><code>def start_requests(self):
    url_lists = []
    for i in range(0,500):
        req = scrapy.Request(self.url.format(url_tags = self.tags[0],url_start = 20*i,url_genres = self.genres[0]))
        url_lists.append(req)
    return url_lists
    

def parse(self, response):
    # 判断该页是否有内容，数值定为20是因为无内容时长度是11
    if len(response.body) &gt;= 20:
        movie = IDItem()
        dicts = json.loads(response.body)
        data_list = dicts['data']
        for data in data_list:
            movie['ids'] = data['id']
            #...
            yield movie
</code></pre>
<h3 id="2-while-循环实现">2、While 循环实现</h3>
<p>While 循环的思路是先从头开始爬取，使用 <code>parse()</code> 方法进行解析，然后递增页数构造下一页的 URL 请求，再循环解析，直到爬取完最后一页。这样不会发送无用的请求。但是难以利用 scrapy 异步的优势。这里构造下一页请求时需要利用 <code>parse()</code> 方法中的参数，可以使用 meta 方法来传递参数。</p>
<pre><code>def start_requests(self):
    url_lists = []
    for i in range(len(self.genres)):
        dict_meta = {'tag_meta':self.tags[0],'page':0,'genre_meta':self.genres[i]}
        req = scrapy.Request(self.url.format(url_tags = self.tags[0],url_start = 20*0,url_genres = self.genres[i]),meta = dict_meta)
        url_lists.append(req)
    return url_lists
    

def parse(self, response):
    # 判断该页是否爬完，数值定为20是因为无内容时长度是11
    if len(response.body) &gt;= 20:
        movie = IDItem()
        dicts = json.loads(response.body)
        data_list = dicts['data']
        for data in data_list:
            movie['ids'] = data['id']
            #...
            yield movie
        
        # while循环构造url递归爬下一页
        tag_meta = response.meta['tag_meta']
        genre_meta = response.meta['genre_meta']
        page = response.meta['page']
        page += 1
        dict_meta = {'tag_meta':tag_meta,'page':page,'genre_meta':genre_meta}
        yield scrapy.Request(self.url.format(url_tags = tag_meta,url_start = 20*page,url_genres = genre_meta),callback=self.parse,meta=dict_meta)
</code></pre>

       </div>
       <div class="post-footer">
        <div class="meta">
         <div class="info">
          <i class="fa fa-sun-o"></i>
          <span class="date">2020-01-15</span>
          <i class="fa fa-tag"></i>
          
          <a class="tag" href="https://xiong-zh.github.io/yaI-h-rVLi/" title="Python">Python </a>
          
          <a class="tag" href="https://xiong-zh.github.io/RKbXlPuzuF/" title="Scrapy">Scrapy </a>
          
         </div>
        </div>
       </div>
      </div>
      <div class="share">
       <div class="evernote">
        <a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a>
       </div>
       <div class="weibo">
        <a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a>
       </div>
       <div class="twitter">
        <a class="fa fa-twitter" href="http://twitter.com/home?status=,https://xiong-zh.github.io/Python爬取不确定页数网页/,;"></a>
       </div>
      </div>
      <div class="pagination">
       <ul class="clearfix">

        <li class="pre pagbuttons"><a class="btn" role="navigation" href="https://xiong-zh.github.io/Git常用命令/" title="Git常用命令">上一篇</a></li>
         
        
        <li class="next pagbuttons"><a class="btn" role="navigation" href="https://xiong-zh.github.io/Scrapy框架的使用之Item-Pipeline用法/" title=" Scrapy框架的使用之Item Pipeline用法">下一篇</a></li>
        
       </ul>
      </div>
        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: '7691fdf5a3780e9bb3a4',
    clientSecret: 'f4bd6c2287489e6b24a18af94afd54efcd0f55f9',
    repo: 'xiong-zh.github.io',
    owner: 'xiong-zh',
    admin: ['xiong-zh'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          
          
        
     </div>
    </div>
   </div>
  </div>
  <script src="https://xiong-zh.github.io/media/scripts/jquery.js"></script>
  <script src="https://xiong-zh.github.io/media/scripts/jquery-migrate-1.2.1.min.js"></script>
  <script src="https://xiong-zh.github.io/media/scripts/jquery.appear.js"></script>


 </body>
</html>