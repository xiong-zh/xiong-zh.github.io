<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Python爬取不确定页数网页 | ZhangXiong</title>
<meta name="description" content="当地一个比较有趣的小法师，最近在在努力学习厉害的魔法。" />
<link rel="shortcut icon" href="https://xiong-zh.github.io/favicon.ico?v=1582700445808">
<link href="https://cdn.remixicon.com/releases/v1.3.1/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">

<link rel="stylesheet" href="https://xiong-zh.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Python爬取不确定页数网页 | ZhangXiong - Atom Feed" href="https://xiong-zh.github.io/atom.xml">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">


<script async src="https://www.googletagmanager.com/gtag/js?id=UA-156420077-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-156420077-1');
</script>


  </head>
  <body>
    <div class="site-nav has-cover">
      <div class="head">
  <div class="inner">
    <a class="site-name" href="https://xiong-zh.github.io">
        <span>ZhangXiong</span>
    </a>
    <label class="burger" for="burger"></label>
    <input id="burger" type="checkbox">
    <button class="burger">
      <div>
        <span></span>
        <span></span>
      </div>
    </button>
    <nav class="info_nav">
      
        
          <a href="/">回到首页</a>
        
      
        
          <a href="/archives">历史归档</a>
        
      
        
          <a href="/tags">所有标签</a>
        
      
        
          <a href="/documents/" target="_blank">后端图谱</a>
        
      
        
          <a href="/about/">关于｜友链</a>
        
      
    </nav>
  </div>
</div>
    </div>
    <article role="main" class="hentry has-cover">
      
        <div class="entry-cover js-cover" data-src="http://picture.zhangxiong.net/images/blog_picture/cover/050.jpg" data-width="900" data-height="423" style="background-image:url(http://picture.zhangxiong.net/images/blog_picture/cover/050.jpg); height: 80vw;">
          <h1 class="post-title">Python爬取不确定页数网页</h1>
        </div>
      
      <h1 class="entry-title" itemprop="headline">Python爬取不确定页数网页</h1>
      <div class="entry-meta">
        <time class="updated" datetime="2020-01-15 12:12:53">2020-01-15</time>
        <span class="author vcard">
          4 min read
        </span>
      </div>
      <div class="post-content yue">
        <p>我们通常遇到的网站页数展现形式有这么几种：</p>
<ul>
<li>第一种是直观地显示所有页数，显示在页面上。</li>
<li>第二种是不直观显示网页总页数，需要抓包才可以看到，一般来说会有一个 <code>totalPage</code> 参数。</li>
<li><strong>第三种是不知道具体有多少页的网页。</strong></li>
</ul>
<!-- more -->
<p>本文详细分析了如何爬取<strong>不知道具体有多少页的网站</strong>，然后用 scrapy 框架实现了这个过程。</p>
<h2 id="一-问题分析">一、问题分析</h2>
<p>我们通常遇到的网站页数展现形式有这么几种：</p>
<ul>
<li>第一种是直观地显示所有页数，显示在页面上。</li>
<li>第二种是不直观显示网页总页数，需要抓包才可以看到，一般来说会有一个 <code>totalPage</code> 参数。</li>
<li><strong>第三种是不知道具体有多少页的网页。</strong></li>
</ul>
<p>对于，前两种形式的网页，爬取方法非常简单，使用 For 循环从首页爬到尾页就行了，第三种形式则不适用，因为不知道尾页的页数，所以循环到哪一页结束无法判断。</p>
<h2 id="二-解决方案">二、解决方案</h2>
<p>这里有两种解决方式：</p>
<ul>
<li>第一种方式：使用 For 循环，尾页的页数设置一个较大的参数，足够循环爬完所有页面。</li>
<li>第二种方法：使用 While 循环，可以结合 break 语句，也可以设起始循环判断条件为 True，从头开始循环爬取直到爬完最后一页，然后更改判断条件为 False 跳出循环，结束爬取。</li>
</ul>
<h2 id="三-实际案例-scrapy-实现">三、实际案例 ——scrapy 实现</h2>
<h3 id="1-for-循环实现">1、For 循环实现</h3>
<p>Scrapy 中使用 For 循环递归爬取的思路非常简单，即先批量生成所有请求的 URL，包括最后无效的 URL，后续在 parse 方法中添加 if 判断过滤无效请求。</p>
<p><strong>由于 Scrapy 依赖于 Twisted 框架，采用的是异步请求处理方式，可以边发送请求边解析内容，不会被阻塞，但是这种方法会发送很多无用请求。</strong></p>
<pre><code>def start_requests(self):
    url_lists = []
    for i in range(0,500):
        req = scrapy.Request(self.url.format(url_tags = self.tags[0],url_start = 20*i,url_genres = self.genres[0]))
        url_lists.append(req)
    return url_lists
    

def parse(self, response):
    # 判断该页是否有内容，数值定为20是因为无内容时长度是11
    if len(response.body) &gt;= 20:
        movie = IDItem()
        dicts = json.loads(response.body)
        data_list = dicts['data']
        for data in data_list:
            movie['ids'] = data['id']
            #...
            yield movie
</code></pre>
<h3 id="2-while-循环实现">2、While 循环实现</h3>
<p>While 循环的思路是先从头开始爬取，使用 <code>parse()</code> 方法进行解析，然后递增页数构造下一页的 URL 请求，再循环解析，直到爬取完最后一页。这样不会发送无用的请求。但是难以利用 scrapy 异步的优势。这里构造下一页请求时需要利用 <code>parse()</code> 方法中的参数，可以使用 meta 方法来传递参数。</p>
<pre><code>def start_requests(self):
    url_lists = []
    for i in range(len(self.genres)):
        dict_meta = {'tag_meta':self.tags[0],'page':0,'genre_meta':self.genres[i]}
        req = scrapy.Request(self.url.format(url_tags = self.tags[0],url_start = 20*0,url_genres = self.genres[i]),meta = dict_meta)
        url_lists.append(req)
    return url_lists
    

def parse(self, response):
    # 判断该页是否爬完，数值定为20是因为无内容时长度是11
    if len(response.body) &gt;= 20:
        movie = IDItem()
        dicts = json.loads(response.body)
        data_list = dicts['data']
        for data in data_list:
            movie['ids'] = data['id']
            #...
            yield movie
        
        # while循环构造url递归爬下一页
        tag_meta = response.meta['tag_meta']
        genre_meta = response.meta['genre_meta']
        page = response.meta['page']
        page += 1
        dict_meta = {'tag_meta':tag_meta,'page':page,'genre_meta':genre_meta}
        yield scrapy.Request(self.url.format(url_tags = tag_meta,url_start = 20*page,url_genres = genre_meta),callback=self.parse,meta=dict_meta)
</code></pre>

      </div>
      <div class="entry-block">
        <div class="entry-tags">
          
            <a href="https://xiong-zh.github.io/yaI-h-rVLi/">
              Python
            </a>
          
            <a href="https://xiong-zh.github.io/RKbXlPuzuF/">
              Scrapy
            </a>
          
        </div>
      </div>
    </article>
    
      <section class="post-section prev-post">
        <div class="inner">
          <h3>前一篇</h3>
          <a href="https://xiong-zh.github.io/Git常用命令/">
            <strong>Git常用命令</strong>
          </a>
        </div>
      </section>
    
    
      <section class="post-section prev-post">
        <div class="inner">
          <h3>后一篇</h3>
          <a href="https://xiong-zh.github.io/Scrapy框架的使用之Item-Pipeline用法/">
            <strong>Scrapy框架的使用之Item Pipeline用法</strong>
          </a>
        </div>
      </section>
    

    
      
        <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: '7691fdf5a3780e9bb3a4',
    clientSecret: 'f4bd6c2287489e6b24a18af94afd54efcd0f55f9',
    repo: 'xiong-zh.github.io',
    owner: 'xiong-zh',
    admin: ['xiong-zh'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

      

      
    

    <footer class="footer">
  <div class="main">
    <a href="https://xiong-zh.github.io">
      <img class="avatar" src="https://xiong-zh.github.io/images/avatar.png?v=1582700445808" alt="ZhangXiong">
    </a>
    <div class="footer__social">
      
        
          <a href="https://github.com/xiong-zh" target="_blank"><i class="remixicon-github-line"></i></a>
        
      
        
          <a href="https://twitter.com/imzhangxiong" target="_blank"><i class="remixicon-twitter-line"></i></a>
        
      
        
          <a href="https://weibo.com/zhangxiongblog" target="_blank"><i class="remixicon-weibo-line"></i></a>
        
      
        
          <a href="https://www.zhihu.com/people/yisyxi" target="_blank"><i class="remixicon-zhihu-line"></i></a>
        
      
        
          <a href="https://www.facebook.com/xiong.zh.397" target="_blank"><i class="remixicon-facebook-line"></i></a>
        
      
        
      
        
      
        
          <a href="https://www.instagram.com/imzhangxiong/" target="_blank"><i class="remixicon-instagram-line"></i></a>
        
      
        
      
        
      
    </div>
    <p class="footer__sosumi">
      <a href="http://beian.miit.gov.cn/" target="_blank">滇ICP备20001109号</a> | Copyright © 2020 <a href="https://zhangxiong.net/" target="_blank">｜zhangxiong </a> 版权所有
    </p>
    <a class="footer-rss" href="https://xiong-zh.github.io/atom.xml">RSS</a>
  </div>
</footer>

<script src="https://xiong-zh.github.io/media/prism.js"></script>
<script>
  Prism.highlightAll()
</script>

  </body>
</html>
